MODEL:
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  META_ARCHITECTURE: "VideoUISE"
  MASK_ON: True
DATASETS:
  TRAIN: ("ytvis_2019_train",)
  TEST: ("ytvis_2019_val",)
SOLVER:
  IMS_PER_BATCH: 16 # 32 # 
  BASE_LR: 0.0001 # 
  STEPS: (4000,)
  MAX_ITER: 6000
  # STEPS: (40000,)
  # MAX_ITER: 60000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.05
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: False
INPUT:
  DATASET_MAPPER_NAME: "YTVISDatasetMapper"
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  RANDOM_FLIP: "flip_by_clip"
  AUGMENTATIONS: []
  MIN_SIZE_TRAIN: (360, 480)
  MIN_SIZE_TEST: 360
  CROP:
    ENABLED: False
    TYPE: "absolute_range"
    SIZE: (600, 720)
  FORMAT: "RGB"
  # MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  # RANDOM_FLIP: "flip_by_clip"
  # MIN_SIZE_TRAIN: !!python/object/apply:eval ["[int(x * 0.1 * 480) for x in range(5, 21)]"]
  # MIN_SIZE_TRAIN_SAMPLING: "choice"
  # MIN_SIZE_TEST: 360 # 480 # 
  # MAX_SIZE_TRAIN: 1280
  # COLOR_AUG_SSD: True
  # FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 5000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 4
VERSION: 2
# CUDNN_BENCHMARK: True